{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.factors.discrete import DiscreteFactor\n",
    "from pgmpy.models import FactorGraph\n",
    "from pgmpy.inference import BeliefPropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = FactorGraph() ## Create FactorGraph object\n",
    "###############################\n",
    "#   TODO: Define factor functions\n",
    "###############################\n",
    "f = DiscreteFactor(['S1'], [2], [0.85,0.15])\n",
    "g = DiscreteFactor(['S1', 'E1'], [2, 2], [0.1,0.2,0.0,0.5])\n",
    "\n",
    "###############################\n",
    "#   TODO: Add random variables\n",
    "#         and factor functions \n",
    "###############################\n",
    "G.add_nodes_from(['S1','E1'])  ## Add random variables \n",
    "G.add_factors(g)     ## Add factor functions\n",
    "G.add_factors(f)\n",
    "###############################\n",
    "#   TODO: Add the edges for random \n",
    "#   variables and factor functions\n",
    "###############################\n",
    "G.add_edges_from([('S1',f), ('S1',g), ('E1',g)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eliminating: E1: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 501.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |    0.7727 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    0.2273 |\n",
      "+-------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bp = BeliefPropagation(G)\n",
    "###############################\n",
    "#   TODO: Compute the marginal probability\n",
    "###############################\n",
    "P_S1 = bp.query(['S1'])\n",
    "P_S1.normalize()\n",
    "print(P_S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1=0 maximizes the marginal probability P(S1).\n"
     ]
    }
   ],
   "source": [
    "print(\"S1=0 maximizes the marginal probability P(S1).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "| S1    |   phi(S1) |\n",
      "+=======+===========+\n",
      "| S1(0) |    0.6939 |\n",
      "+-------+-----------+\n",
      "| S1(1) |    0.3061 |\n",
      "+-------+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "P_S1_E1 = bp.query(['S1'], evidence={'E1':1})\n",
    "P_S1_E1.normalize()\n",
    "print(P_S1_E1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most probable state when observing E1=1 is S1=0.\n"
     ]
    }
   ],
   "source": [
    "print(\"The most probable state when observing E1=1 is S1=0.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ATTACK_EVENTS_MAP = {\n",
    "    'Scan':1,\n",
    "    'Login':2,\n",
    "    'Sensitive_URI':3,\n",
    "    'New_Kernel_Module':4,\n",
    "    'DNS_Tunneling':5\n",
    "}\n",
    "ATTACK_STATES_MAP = {\n",
    "    'benign': 1,\n",
    "    'discovery': 2,\n",
    "    'access': 3,\n",
    "    'lateral_movement': 4,\n",
    "    'privilege_escalation': 5,\n",
    "    'persistence': 6,\n",
    "    'defense_evasion': 7,\n",
    "    'collection': 8,\n",
    "    'exfiltration': 9,\n",
    "    'command_control': 10,\n",
    "    'execution': 11\n",
    "}\n",
    "\n",
    "FACTOR_FUNCTION_MAP = {\n",
    "    'Scan': [0] * 11,\n",
    "    'Login': [0] * 11,\n",
    "    'Sensitive_URI': [0] * 11,\n",
    "    'New_Kernel_Module': [0] * 11,\n",
    "    'DNS_Tunneling': [0] * 11\n",
    "}\n",
    "\n",
    "SEQUENCE_EVENT_MAP = {'e1': 'Scan',\n",
    "                      'e2': 'Login',\n",
    "                      'e3': 'Sensitive_URI',\n",
    "                      'e4': 'Sensitive_URI',\n",
    "                      'e5': 'Sensitive_URI',\n",
    "                      'e6': 'New_Kernel_Module',\n",
    "                      'e7': 'DNS_Tunneling',\n",
    "                      'e8': 'DNS_Tunneling',\n",
    "                      'e9': 'DNS_Tunneling'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6    7     8    9   10\n",
       "0  0.02  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.98  0.0  0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_review = open('data/event_review.txt', 'r') \n",
    "event_reviews = event_review.readlines()\n",
    "\n",
    "events = ['Scan','Login']+['Sensitive_URI']*3+['New_Kernel_Module']+['DNS_Tunneling']*3\n",
    "facfuncs = []\n",
    "for line in event_reviews:\n",
    "    #print(\"Line: \", line)\n",
    "    for attack_event in ATTACK_EVENTS_MAP.keys():\n",
    "        if attack_event in line:\n",
    "            #print(\"   Attack Event: \", attack_event)\n",
    "            for attack_state in ATTACK_STATES_MAP.keys():\n",
    "                if attack_state in line:\n",
    "                    #print(\"   Attack State: \", attack_state)\n",
    "                    attack_state_index = ATTACK_STATES_MAP[attack_state]-1\n",
    "                    FACTOR_FUNCTION_MAP[attack_event][attack_state_index] += 1\n",
    "                    break\n",
    "            break\n",
    "    #FACTOR_FUNCTION_MAP[attack_event][ATTACK_STATES_MAP[attack_state]-1] += 1\n",
    "for _, function in FACTOR_FUNCTION_MAP.items():\n",
    "    total = sum(function)\n",
    "    for i in range(len(function)):\n",
    "        function[i] = function[i]/total\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(FACTOR_FUNCTION_MAP['DNS_Tunneling']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Scan', 'Sensitive_URI', 'New_Kernel_Module'), 200)\n",
      "(('Sensitive_URI', 'Sensitive_URI', 'Sensitive_URI'), 186)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "attack_events = []\n",
    "attack_states = []\n",
    "\n",
    "attack_sequences = open('data/attack_sequences.txt', 'r').readlines()\n",
    "\n",
    "count = 0\n",
    "commons = defaultdict(int)\n",
    "\n",
    "for sequence in attack_sequences:\n",
    "    sequence = sequence.split(' ')[:-1]\n",
    "    j = 3\n",
    "    while j <= len(sequence):\n",
    "        commons[tuple(sequence[j-3:j])] += 1\n",
    "        j += 1\n",
    "\n",
    "repetitives = defaultdict(int)\n",
    "\n",
    "for key, value in commons.items():\n",
    "    if key[0] == key[1] and key[1] == key[2]:\n",
    "        repetitives[key] = value\n",
    "        \n",
    "most_common_sequence = max(commons.items(), key=lambda item: item[1])\n",
    "most_frequent_repetitive_sequence = max(repetitives.items(), key=lambda item: item[1])\n",
    "print(most_common_sequence)\n",
    "print(most_frequent_repetitive_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 186 2798\n"
     ]
    }
   ],
   "source": [
    "countc = 0\n",
    "countr = 0\n",
    "total = 0\n",
    "for sequence in attack_sequences:\n",
    "    sequence = sequence.split(' ')[:-1]\n",
    "    j=3\n",
    "    while j<=len(sequence):\n",
    "        if tuple(sequence[j-3:j]) == ('Scan','Sensitive_URI','New_Kernel_Module'):\n",
    "            countc += 1\n",
    "        elif tuple(sequence[j-3:j]) == ('Sensitive_URI','Sensitive_URI','Sensitive_URI'):\n",
    "            countr += 1\n",
    "        total += 1\n",
    "        j+=1\n",
    "\n",
    "probsc, probsr = [0,0,0,0,0,countc/total,0,0,0,0,0], [0,0,0,0,countr/total,0,0,0,0,0,0]\n",
    "print(countc,countr,total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2  You will have to submit the graph you draw through Compass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eliminating: e1: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 250.74it/s]\n",
      "Eliminating: e2: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 338.41it/s]\n",
      "Eliminating: e3: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 333.97it/s]\n",
      "Eliminating: e4: 100%|█████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1034.86it/s]\n",
      "Eliminating: e5: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 251.59it/s]\n",
      "Eliminating: e6: 100%|██████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 214.83it/s]\n",
      "Eliminating: e7: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 501.77it/s]\n",
      "Eliminating: e8: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 250.78it/s]\n",
      "Eliminating: e9: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 250.63it/s]\n"
     ]
    }
   ],
   "source": [
    "### Method 1: Keep the original graph, and create 5 subgraphs\n",
    "\n",
    "G1 = FactorGraph() \n",
    "f_1 = DiscreteFactor(['e1','s1'],[1,11],FACTOR_FUNCTION_MAP['Scan'])\n",
    "f_3 = DiscreteFactor(['e3','s3'],[1,11],FACTOR_FUNCTION_MAP['Sensitive_URI'])\n",
    "f_4 = DiscreteFactor(['e4','s4'],[1,11],FACTOR_FUNCTION_MAP['Sensitive_URI'])\n",
    "f_5 = DiscreteFactor(['e5','s5'],[1,11],FACTOR_FUNCTION_MAP['Sensitive_URI'])\n",
    "f_6 = DiscreteFactor(['e6','s6'],[1,11],FACTOR_FUNCTION_MAP['New_Kernel_Module'])\n",
    "\n",
    "r = DiscreteFactor(['e3','e4','e5','s5'],[1,1,1,11],probsr)\n",
    "c = DiscreteFactor(['e1','e3','e6','s6'],[1,1,1,11],probsc)\n",
    "\n",
    "nodes1 = ['e1','e3','e4','e5','e6','s1','s3','s4','s5','s6',]\n",
    "G1.add_nodes_from(nodes1) \n",
    "G1.add_factors(f_1, f_3, f_4, f_5, f_6, r, c)\n",
    "\n",
    "G1.add_edges_from([('e1',c), ('e3',c), ('e6',c), ('s6',c),\n",
    "                  ('e3',r), ('e4',r), ('e5',r), ('s5',r),\n",
    "                  ('e1',f_1), ('s1',f_1), ('e3',f_3), ('s3',f_3), \n",
    "                  ('e4',f_4), ('s4',f_4), ('e5',f_5), ('s5',f_5), \n",
    "                  ('e6',f_6), ('s6',f_6),])\n",
    "\n",
    "bp1 = BeliefPropagation(G1)\n",
    "\n",
    "\n",
    "G2 = FactorGraph()\n",
    "f_2 = DiscreteFactor(['e2','s2'],[1,11],FACTOR_FUNCTION_MAP['Login'])\n",
    "nodes2 = ['e2','s2']\n",
    "G2.add_nodes_from(nodes2)  ## Add random variables \n",
    "G2.add_factors(f_2)\n",
    "G2.add_edges_from([('e2',f_2), ('s2',f_2)])\n",
    "bp2 = BeliefPropagation(G2)\n",
    "\n",
    "G3 = FactorGraph()\n",
    "f_7 = DiscreteFactor(['e7','s7'],[1,11],FACTOR_FUNCTION_MAP['DNS_Tunneling'])\n",
    "nodes3 = ['e7','s7']\n",
    "G3.add_nodes_from(nodes3)  ## Add random variables \n",
    "G3.add_factors(f_7)\n",
    "G3.add_edges_from([('e7',f_7), ('s7',f_7)])\n",
    "bp3 = BeliefPropagation(G3)\n",
    "\n",
    "G4 = FactorGraph()\n",
    "f_8 = DiscreteFactor(['e8','s8'],[1,11],FACTOR_FUNCTION_MAP['DNS_Tunneling'])\n",
    "nodes4 = ['e8','s8']\n",
    "G4.add_nodes_from(nodes4)  ## Add random variables \n",
    "G4.add_factors(f_8)\n",
    "G4.add_edges_from([('e8',f_8), ('s8',f_8)])\n",
    "bp4 = BeliefPropagation(G4)\n",
    "\n",
    "G5 = FactorGraph()\n",
    "f_9 = DiscreteFactor(['e9','s9'],[1,11],FACTOR_FUNCTION_MAP['DNS_Tunneling'])\n",
    "nodes5 = ['e9','s9']\n",
    "G5.add_nodes_from(nodes5)  ## Add random variables \n",
    "G5.add_factors(f_9)\n",
    "G5.add_edges_from([('e9',f_9), ('s9',f_9)])\n",
    "bp5 = BeliefPropagation(G5)\n",
    "\n",
    "P_s1 = bp1.query(['s1'])\n",
    "P_s2 = bp2.query(['s2'])\n",
    "P_s3 = bp1.query(['s3'])\n",
    "P_s4 = bp1.query(['s4'])\n",
    "P_s5 = bp1.query(['s5'])\n",
    "P_s6 = bp1.query(['s6'])\n",
    "P_s7 = bp3.query(['s7'])\n",
    "P_s8 = bp4.query(['s8'])\n",
    "P_s9 = bp5.query(['s9'])\n",
    "P_s1.normalize()\n",
    "P_s2.normalize()\n",
    "P_s3.normalize()\n",
    "P_s4.normalize()\n",
    "P_s5.normalize()\n",
    "P_s6.normalize()\n",
    "P_s7.normalize()\n",
    "P_s8.normalize()\n",
    "P_s9.normalize()\n",
    "P_s1,P_s2,P_s3,P_s4,P_s5,P_s6,P_s7,P_s8,P_s9 = P_s1.values,P_s2.values,P_s3.values,P_s4.values,P_s5.values,P_s6.values,P_s7.values,P_s8.values,P_s9.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "Eliminating: e2: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 500.87it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "Eliminating: e7: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 334.29it/s]\n",
      "Eliminating: e8: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 250.65it/s]\n",
      "Eliminating: e9: 100%|██████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 500.69it/s]\n"
     ]
    }
   ],
   "source": [
    "### Method 2: Prune the original factor graph, and create 9 subgraphs\n",
    "\n",
    "G1 = FactorGraph()\n",
    "f_1 = DiscreteFactor(['s1'],[11],FACTOR_FUNCTION_MAP['Scan'])\n",
    "nodes1 = ['s1']\n",
    "G1.add_nodes_from(nodes1)  ## Add random variables \n",
    "G1.add_factors(f_1)\n",
    "G1.add_edges_from([('s1',f_1)])\n",
    "bp1 = BeliefPropagation(G1)\n",
    "\n",
    "G2 = FactorGraph()\n",
    "f_2 = DiscreteFactor(['e2','s2'],[1,11],FACTOR_FUNCTION_MAP['Login'])\n",
    "nodes2 = ['e2','s2']\n",
    "G2.add_nodes_from(nodes2)  ## Add random variables \n",
    "G2.add_factors(f_2)\n",
    "G2.add_edges_from([('e2',f_2), ('s2',f_2)])\n",
    "bp2 = BeliefPropagation(G2)\n",
    "\n",
    "G3 = FactorGraph()\n",
    "f_3 = DiscreteFactor(['s3'],[11],FACTOR_FUNCTION_MAP['Sensitive_URI'])\n",
    "nodes3 = ['s3']\n",
    "G3.add_nodes_from(nodes3)  ## Add random variables \n",
    "G3.add_factors(f_3)\n",
    "G3.add_edges_from([('s3',f_3)])\n",
    "bp3 = BeliefPropagation(G3)\n",
    "\n",
    "G4 = FactorGraph()\n",
    "f_4 = DiscreteFactor(['s4'],[11],FACTOR_FUNCTION_MAP['Sensitive_URI'])\n",
    "nodes4 = ['s4']\n",
    "G4.add_nodes_from(nodes4)  ## Add random variables \n",
    "G4.add_factors(f_4)\n",
    "G4.add_edges_from([('s4',f_4)])\n",
    "bp4 = BeliefPropagation(G4)\n",
    "\n",
    "G5 = FactorGraph()\n",
    "f_5 = DiscreteFactor(['s5'],[11],FACTOR_FUNCTION_MAP['Sensitive_URI'])\n",
    "r = DiscreteFactor(['s5'],[11],probsr)\n",
    "nodes5 = ['s5']\n",
    "G5.add_nodes_from(nodes5)  ## Add random variables \n",
    "G5.add_factors(f_5, r)\n",
    "G5.add_edges_from([('s5',r), ('s5',f_5)])\n",
    "bp5 = BeliefPropagation(G5)\n",
    "\n",
    "G6 = FactorGraph()\n",
    "f_6 = DiscreteFactor(['s6'],[11],FACTOR_FUNCTION_MAP['Sensitive_URI'])\n",
    "c = DiscreteFactor(['s6'],[11],probsr)\n",
    "nodes6 = ['s6']\n",
    "G6.add_nodes_from(nodes6)  ## Add random variables \n",
    "G6.add_factors(f_6, c)\n",
    "G6.add_edges_from([('s6',c), ('s6',f_6)])\n",
    "bp6 = BeliefPropagation(G6)\n",
    "\n",
    "G7 = FactorGraph()\n",
    "f_7 = DiscreteFactor(['e7','s7'],[1,11],FACTOR_FUNCTION_MAP['DNS_Tunneling'])\n",
    "nodes7 = ['e7','s7']\n",
    "G7.add_nodes_from(nodes7)  ## Add random variables \n",
    "G7.add_factors(f_7)\n",
    "G7.add_edges_from([('e7',f_7), ('s7',f_7)])\n",
    "bp7 = BeliefPropagation(G7)\n",
    "\n",
    "G8 = FactorGraph()\n",
    "f_8 = DiscreteFactor(['e8','s8'],[1,11],FACTOR_FUNCTION_MAP['DNS_Tunneling'])\n",
    "nodes8 = ['e8','s8']\n",
    "G8.add_nodes_from(nodes8)  ## Add random variables \n",
    "G8.add_factors(f_8)\n",
    "G8.add_edges_from([('e8',f_8), ('s8',f_8)])\n",
    "bp8 = BeliefPropagation(G8)\n",
    "\n",
    "G9 = FactorGraph()\n",
    "f_9 = DiscreteFactor(['e9','s9'],[1,11],FACTOR_FUNCTION_MAP['DNS_Tunneling'])\n",
    "nodes9 = ['e9','s9']\n",
    "G9.add_nodes_from(nodes9)  ## Add random variables \n",
    "G9.add_factors(f_9)\n",
    "G9.add_edges_from([('e9',f_9), ('s9',f_9)])\n",
    "bp9 = BeliefPropagation(G9)\n",
    "\n",
    "P_s1 = bp1.query(['s1'])\n",
    "P_s2 = bp2.query(['s2'])\n",
    "P_s3 = bp3.query(['s3'])\n",
    "P_s4 = bp4.query(['s4'])\n",
    "P_s5 = bp5.query(['s5'])\n",
    "P_s6 = bp6.query(['s6'])\n",
    "P_s7 = bp7.query(['s7'])\n",
    "P_s8 = bp8.query(['s8'])\n",
    "P_s9 = bp9.query(['s9'])\n",
    "P_s1.normalize()\n",
    "P_s2.normalize()\n",
    "P_s3.normalize()\n",
    "P_s4.normalize()\n",
    "P_s5.normalize()\n",
    "P_s6.normalize()\n",
    "P_s7.normalize()\n",
    "P_s8.normalize()\n",
    "P_s9.normalize()\n",
    "P_s1,P_s2,P_s3,P_s4,P_s5,P_s6,P_s7,P_s8,P_s9 = P_s1.values,P_s2.values,P_s3.values,P_s4.values,P_s5.values,P_s6.values,P_s7.values,P_s8.values,P_s9.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. At every time point, provide the marginal probability of each state (Since we have 9 time points and 11 possible states, you should provide 99 probability values here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1    2    3         4    5    6    7     8    9   10\n",
       "0  0.936000  0.064  0.0  0.0  0.000000  0.0  0.0  0.0  0.00  0.0  0.0\n",
       "1  1.000000  0.000  0.0  0.0  0.000000  0.0  0.0  0.0  0.00  0.0  0.0\n",
       "2  0.553333  0.000  0.0  0.0  0.446667  0.0  0.0  0.0  0.00  0.0  0.0\n",
       "3  0.553333  0.000  0.0  0.0  0.446667  0.0  0.0  0.0  0.00  0.0  0.0\n",
       "4  0.000000  0.000  0.0  0.0  1.000000  0.0  0.0  0.0  0.00  0.0  0.0\n",
       "5  0.000000  0.000  0.0  0.0  1.000000  0.0  0.0  0.0  0.00  0.0  0.0\n",
       "6  0.020000  0.000  0.0  0.0  0.000000  0.0  0.0  0.0  0.98  0.0  0.0\n",
       "7  0.020000  0.000  0.0  0.0  0.000000  0.0  0.0  0.0  0.98  0.0  0.0\n",
       "8  0.020000  0.000  0.0  0.0  0.000000  0.0  0.0  0.0  0.98  0.0  0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([P_s1,P_s2, P_s3, P_s4, P_s5, P_s6,P_s7, P_s8, P_s9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. At every time point, provide the most probable state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most probable states for s1-s9 are benign, benign, benign, benign, privilege_escalation, persistence, exfiltration, exfiltration, exfiltration\n"
     ]
    }
   ],
   "source": [
    "print(\"The most probable states for s1-s9 are benign, benign, benign, benign, privilege_escalation, persistence, exfiltration, exfiltration, exfiltration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The recommended actions are No-Op, No-Op, No-Op, No-Op, Monitor, Monitor, Stop Attack, Stop Attack, Stop Attack.\n"
     ]
    }
   ],
   "source": [
    "ACTIONS = {\n",
    "    # each value in an actions' vector corresponds to an attack stage\n",
    "    'NO-OP':   [1.,   0.61, 0.69, 0.09, 0.2 , 0. ,  0.,   0.,   0. ,  0. ,  0.  ],\n",
    "    'MONITOR': [0.  , 0.39, 0.31 ,0.84, 0.63, 0.7,  0.07 ,0.1 , 0. ,  0. ,  0.  ],\n",
    "    'STOP':    [0.  , 0.,   0.  , 0.07, 0.17, 0.3,  0.93 ,0.9 , 1. ,  1. ,  1.  ]\n",
    "}\n",
    "print(\"The recommended actions are No-Op, No-Op, No-Op, No-Op, Monitor, Monitor, Stop Attack, Stop Attack, Stop Attack.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicate the earliest stage in which your model should recommend stopping the attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The earliest stage to stop the attack is s7.\n"
     ]
    }
   ],
   "source": [
    "print(\"The earliest stage to stop the attack is s7.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Judge whether the most probable states for $s_1-s_6,s_8,s_9$ remain the same as Task3.2\n",
    "#### b. State the reason for your judgement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most probable states should remain the same as Task 3.2 because the subgraph e7 and s7 are disconnected to the rest of the graph.\n"
     ]
    }
   ],
   "source": [
    "print (\"The most probable states should remain the same as Task 3.2 because the subgraph e7 and s7 are disconnected to the rest of the graph.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Draw an HMM model for the attack scenario given the provided states and events.\n",
    "#### b. What parameters are needed for this HMM model to work?\n",
    "#### c. Give an example of an advantage of the FG over the HMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8a See drawing in the slides.\n",
      "3.8b The transition probability matrix, the observation matrix, and the initial distribution for the hidden state: P(S1), P(S2|S1), P(S3|S2), P(S4|S3), P(S5|S4), P(S6|S5), P(S7|S6), P(S8|S7), P(S9|S8), P(E1|S1), P(E2|S2), P(E3|S3), P(E4|S4), P(E5|S5), P(E6|S6), P(E7|S7), P(E8|S8), P(E9|S9).\n",
      "3.8c Give an example of an advantage of the FG over the HMM model. FG is a generalization of the HMM model. One of its advantages over HMM is that it can model the relationship between multiple evidences and an underlying state. (E.g. links between the repetitive events and the attack stage) This is impossible for HMM because HMM assumes that the hidden states have a temporal order, which does not apply to many situations.\n"
     ]
    }
   ],
   "source": [
    "print(\"3.8a See drawing in the slides.\")\n",
    "print(\"3.8b The transition probability matrix, the observation matrix, and the initial distribution for the hidden state: P(S1), P(S2|S1), P(S3|S2), P(S4|S3), P(S5|S4), P(S6|S5), P(S7|S6), P(S8|S7), P(S9|S8), P(E1|S1), P(E2|S2), P(E3|S3), P(E4|S4), P(E5|S5), P(E6|S6), P(E7|S7), P(E8|S8), P(E9|S9).\")\n",
    "print(\"3.8c Give an example of an advantage of the FG over the HMM model. FG is a generalization of the HMM model. One of its advantages over HMM is that it can model the relationship between multiple evidences and an underlying state. (E.g. links between the repetitive events and the attack stage) This is impossible for HMM because HMM assumes that the hidden states have a temporal order, which does not apply to many situations.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
